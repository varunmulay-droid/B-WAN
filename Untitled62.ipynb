{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPCTPak5lIqDCALUEro5k47",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/varunmulay-droid/B-WAN/blob/main/Untitled62.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 663
        },
        "id": "Y2_o5FaupTcd",
        "outputId": "511fb9f6-434e-4c8e-bee9-361196365c76"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… Drive dataset directory ensured: /content/drive/MyDrive/Wan21_QLoRA/dataset\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-3885731704.py:497: DeprecationWarning: The 'css' parameter in the Blocks constructor will be removed in Gradio 6.0. You will need to pass 'css' to Blocks.launch() instead.\n",
            "  with gr.Blocks(css=CSS, title=\"Wan 2.1 Dataset Creator\") as demo:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://ec9a80af120cdd3be4.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://ec9a80af120cdd3be4.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "import os, gc, json, base64, shutil, zipfile, time, re, tempfile, threading\n",
        "from pathlib import Path\n",
        "from typing import List, Tuple, Optional\n",
        "\n",
        "import cv2\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "import requests\n",
        "import gradio as gr\n",
        "\n",
        "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
        "# OPENROUTER VISION MODELS AVAILABLE\n",
        "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
        "OPENROUTER_MODELS = {\n",
        "    \"ğŸ”¥ Google Gemini 2.0 Flash (Fast & Cheap)\": \"google/gemini-2.0-flash-001\",\n",
        "    \"âš¡ Google Gemini Flash 1.5 8B (Fastest)\": \"google/gemini-flash-1.5-8b\",\n",
        "    \"ğŸ§  Google Gemini 2.0 Flash Thinking\": \"google/gemini-2.0-flash-thinking-exp:free\",\n",
        "    \"ğŸ’ Claude 3.5 Haiku (Balanced)\": \"anthropic/claude-3.5-haiku\",\n",
        "    \"ğŸŒŸ GPT-4o Mini (Reliable)\": \"openai/gpt-4o-mini\",\n",
        "    \"ğŸš€ Llama 3.2 11B Vision (Free)\": \"meta-llama/llama-3.2-11b-vision-instruct:free\",\n",
        "    \"ğŸ¦™ Llama 3.2 90B Vision\": \"meta-llama/llama-3.2-90b-vision-instruct\",\n",
        "    \"ğŸ”® Qwen2.5 VL 72B (Free)\": \"qwen/qwen2.5-vl-72b-instruct:free\",\n",
        "    \"ğŸŒ€ Mistral Pixtral 12B\": \"mistralai/pixtral-12b\",\n",
        "    \"ğŸ¯ GPT-4o (Best Quality)\": \"openai/gpt-4o\",\n",
        "}\n",
        "\n",
        "CAPTION_STYLES = {\n",
        "    \"Wan T2V Training (Detailed)\": (\n",
        "        \"You are an expert video captioner for text-to-video AI model training. \"\n",
        "        \"Analyze these frames from a video clip and write ONE single descriptive caption. \"\n",
        "        \"The caption should: describe the main subject and action, mention visual style/mood, \"\n",
        "        \"include camera motion if apparent, describe lighting and colors, be 1-3 sentences, \"\n",
        "        \"be written as a natural language prompt. Do NOT use bullet points or numbered lists. \"\n",
        "        \"Output ONLY the caption text, nothing else.\"\n",
        "    ),\n",
        "    \"Short & Concise (1 sentence)\": (\n",
        "        \"Describe this video in exactly ONE concise sentence suitable for text-to-video model training. \"\n",
        "        \"Focus on the main subject and action. Output ONLY the caption, nothing else.\"\n",
        "    ),\n",
        "    \"CogVideoX Style\": (\n",
        "        \"Write a detailed video caption for AI training in the CogVideoX style. \"\n",
        "        \"Start with the main subject, describe motion, environment, lighting, camera angle. \"\n",
        "        \"Use present tense. Be cinematic and descriptive. 2-4 sentences. Output ONLY the caption.\"\n",
        "    ),\n",
        "    \"LAION Style (Tag-based)\": (\n",
        "        \"Describe this video using comma-separated descriptive tags and a short sentence. \"\n",
        "        \"Format: [subject], [action], [setting], [style], [mood]. Then one sentence summary. \"\n",
        "        \"Output ONLY this, nothing else.\"\n",
        "    ),\n",
        "    \"Custom (use prefix box below)\": \"CUSTOM\",\n",
        "}\n",
        "\n",
        "# Define DRIVE_DATASET_DIR here to ensure it's globally accessible\n",
        "DRIVE_DATASET_DIR = '/content/drive/MyDrive/Wan21_QLoRA/dataset'\n",
        "os.makedirs(DRIVE_DATASET_DIR, exist_ok=True)\n",
        "print(f'âœ… Drive dataset directory ensured: {DRIVE_DATASET_DIR}')\n",
        "\n",
        "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
        "# CORE FUNCTIONS\n",
        "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
        "\n",
        "def extract_frames(video_path: str, n_frames: int = 4, target_size: int = 512) -> List[str]:\n",
        "    \"\"\"\n",
        "    Extract n evenly-spaced frames from a video.\n",
        "    Returns list of base64-encoded JPEG strings.\n",
        "    \"\"\"\n",
        "    cap = cv2.VideoCapture(video_path)\n",
        "    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
        "    if total_frames == 0:\n",
        "        cap.release()\n",
        "        raise ValueError(f\"Could not read video: {video_path}\")\n",
        "\n",
        "    indices = np.linspace(0, total_frames - 1, n_frames, dtype=int)\n",
        "    b64_frames = []\n",
        "\n",
        "    for idx in indices:\n",
        "        cap.set(cv2.CAP_PROP_POS_FRAMES, idx)\n",
        "        ret, frame = cap.read()\n",
        "        if not ret:\n",
        "            continue\n",
        "        # Resize keeping aspect ratio\n",
        "        h, w = frame.shape[:2]\n",
        "        if max(h, w) > target_size:\n",
        "            scale = target_size / max(h, w)\n",
        "            frame = cv2.resize(frame, (int(w * scale), int(h * scale)))\n",
        "        # Encode to JPEG base64\n",
        "        _, buf = cv2.imencode('.jpg', frame, [cv2.IMWRITE_JPEG_QUALITY, 85])\n",
        "        b64 = base64.b64encode(buf.tobytes()).decode('utf-8')\n",
        "        b64_frames.append(b64)\n",
        "\n",
        "    cap.release()\n",
        "    return b64_frames\n",
        "\n",
        "\n",
        "def get_video_info(video_path: str) -> dict:\n",
        "    \"\"\"Get basic video metadata.\"\"\"\n",
        "    cap = cv2.VideoCapture(video_path)\n",
        "    info = {\n",
        "        'fps': cap.get(cv2.CAP_PROP_FPS),\n",
        "        'frames': int(cap.get(cv2.CAP_PROP_FRAME_COUNT)),\n",
        "        'width': int(cap.get(cv2.CAP_PROP_FRAME_WIDTH)),\n",
        "        'height': int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT)),\n",
        "    }\n",
        "    info['duration'] = info['frames'] / max(info['fps'], 1)\n",
        "    cap.release()\n",
        "    return info\n",
        "\n",
        "\n",
        "def generate_caption_openrouter(\n",
        "    b64_frames: List[str],\n",
        "    api_key: str,\n",
        "    model_id: str,\n",
        "    system_prompt: str,\n",
        "    custom_prefix: str = \"\",\n",
        ") -> str:\n",
        "    \"\"\"\n",
        "    Call OpenRouter vision API with multiple frames.\n",
        "    Returns the generated caption string.\n",
        "    \"\"\"\n",
        "    if system_prompt == \"CUSTOM\":\n",
        "        system_prompt = (\n",
        "            custom_prefix.strip() or\n",
        "            \"Describe this video clip in detail for text-to-video AI training. Output ONLY the caption.\"\n",
        "        )\n",
        "\n",
        "    # Build content: interleave text + images\n",
        "    content = [\n",
        "        {\n",
        "            \"type\": \"text\",\n",
        "            \"text\": f\"Here are {len(b64_frames)} frames extracted from a video clip (beginning, middle, end). \"\n",
        "                    \"Based on these frames, \" + system_prompt\n",
        "        }\n",
        "    ]\n",
        "    for i, b64 in enumerate(b64_frames):\n",
        "        content.append({\n",
        "            \"type\": \"image_url\",\n",
        "            \"image_url\": {\n",
        "                \"url\": f\"data:image/jpeg;base64,{b64}\",\n",
        "                \"detail\": \"low\",  # saves tokens\n",
        "            }\n",
        "        })\n",
        "\n",
        "    payload = {\n",
        "        \"model\": model_id,\n",
        "        \"messages\": [\n",
        "            {\"role\": \"user\", \"content\": content}\n",
        "        ],\n",
        "        \"max_tokens\": 300,\n",
        "        \"temperature\": 0.7,\n",
        "    }\n",
        "\n",
        "    headers = {\n",
        "        \"Authorization\": f\"Bearer {api_key}\",\n",
        "        \"Content-Type\": \"application/json\",\n",
        "        \"HTTP-Referer\": \"https://colab.research.google.com\",\n",
        "        \"X-Title\": \"Wan2.1 Dataset Creator\",\n",
        "    }\n",
        "\n",
        "    response = requests.post(\n",
        "        \"https://openrouter.ai/api/v1/chat/completions\",\n",
        "        json=payload,\n",
        "        headers=headers,\n",
        "        timeout=60,\n",
        "    )\n",
        "\n",
        "    if response.status_code != 200:\n",
        "        err = response.json()\n",
        "        raise RuntimeError(f\"OpenRouter API error {response.status_code}: {err.get('error', {}).get('message', str(err))}\")\n",
        "\n",
        "    result = response.json()\n",
        "    caption = result['choices'][0]['message']['content'].strip()\n",
        "    # Clean up any unwanted prefixes\n",
        "    caption = re.sub(r'^(Caption:|Description:|Output:)\\s*', '', caption, flags=re.IGNORECASE)\n",
        "    return caption\n",
        "\n",
        "\n",
        "def sanitize_filename(name: str) -> str:\n",
        "    \"\"\"Make a safe filename from video name.\"\"\"\n",
        "    name = Path(name).stem  # remove extension\n",
        "    name = re.sub(r'[^\\w\\-_]', '_', name)\n",
        "    name = re.sub(r'_+', '_', name).strip('_')\n",
        "    return name[:60]  # cap length\n",
        "\n",
        "\n",
        "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
        "# MAIN PROCESSING PIPELINE\n",
        "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
        "\n",
        "def process_videos(\n",
        "    video_files,\n",
        "    api_key: str,\n",
        "    model_display_name: str,\n",
        "    caption_style: str,\n",
        "    custom_prefix: str,\n",
        "    n_frames: int,\n",
        "    save_to_drive: bool,\n",
        "    caption_prefix: str,\n",
        "    caption_suffix: str,\n",
        "    progress=gr.Progress(track_tqdm=True),\n",
        "):\n",
        "    \"\"\"\n",
        "    Full pipeline: video files â†’ captions â†’ dataset folder + zip.\n",
        "    Yields log messages and final outputs.\n",
        "    \"\"\"\n",
        "    logs = []\n",
        "    results_data = []  # [{name, caption, status}]\n",
        "\n",
        "    def log(msg):\n",
        "        logs.append(msg)\n",
        "        return \"\\n\".join(logs)\n",
        "\n",
        "    # â”€â”€ Validate inputs â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "    if not api_key or not api_key.strip():\n",
        "        yield log(\"âŒ ERROR: Please enter your OpenRouter API key.\"), None, None, gr.update()\n",
        "        return\n",
        "\n",
        "    if not video_files:\n",
        "        yield log(\"âŒ ERROR: Please upload at least one video.\"), None, None, gr.update()\n",
        "        return\n",
        "\n",
        "    model_id = OPENROUTER_MODELS.get(model_display_name, \"google/gemini-2.0-flash-001\")\n",
        "    system_prompt = CAPTION_STYLES.get(caption_style, CAPTION_STYLES[\"Wan T2V Training (Detailed)\"])\n",
        "\n",
        "    # â”€â”€ Setup output directory â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "    timestamp = time.strftime(\"%Y%m%d_%H%M%S\")\n",
        "    local_out = f\"/content/dataset_{timestamp}\"\n",
        "    os.makedirs(local_out, exist_ok=True)\n",
        "\n",
        "    yield log(f\"ğŸš€ Starting dataset creation â€” {len(video_files)} video(s)\"), None, None, gr.update(visible=True)\n",
        "    yield log(f\"   Model    : {model_display_name}\"), None, None, gr.update(visible=True)\n",
        "    yield log(f\"   Style    : {caption_style}\"), None, None, gr.update(visible=True)\n",
        "    yield log(f\"   Frames   : {n_frames} per video\"), None, None, gr.update(visible=True)\n",
        "    yield log(f\"   Output   : {local_out}\\n\"), None, None, gr.update(visible=True)\n",
        "\n",
        "    # â”€â”€ Process each video â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "    for i, video_file in enumerate(video_files, 1):\n",
        "        video_path = video_file if isinstance(video_file, str) else video_file.name\n",
        "        orig_name  = os.path.basename(video_path)\n",
        "        safe_name  = sanitize_filename(orig_name)\n",
        "\n",
        "        yield log(f\"[{i}/{len(video_files)}] ğŸ“¹ Processing: {orig_name}\"), None, None, gr.update(visible=True)\n",
        "\n",
        "        try:\n",
        "            # Video info\n",
        "            info = get_video_info(video_path)\n",
        "            yield log(f\"   ğŸ“Š {info['width']}x{info['height']} | {info['duration']:.1f}s | {info['fps']:.0f}fps\"), None, None, gr.update(visible=True)\n",
        "\n",
        "            # Extract frames\n",
        "            yield log(f\"   ğŸ–¼ï¸  Extracting {n_frames} frames...\"), None, None, gr.update(visible=True)\n",
        "            b64_frames = extract_frames(video_path, n_frames=n_frames)\n",
        "            yield log(f\"   âœ… Got {len(b64_frames)} frames\"), None, None, gr.update(visible=True)\n",
        "\n",
        "            # Generate caption\n",
        "            yield log(f\"   ğŸ¤– Sending to {model_id}...\"), None, None, gr.update(visible=True)\n",
        "            caption_raw = generate_caption_openrouter(\n",
        "                b64_frames, api_key.strip(), model_id, system_prompt, custom_prefix\n",
        "            )\n",
        "\n",
        "            # Apply prefix/suffix\n",
        "            caption = caption_raw\n",
        "            if caption_prefix.strip():\n",
        "                caption = caption_prefix.strip() + \", \" + caption\n",
        "            if caption_suffix.strip():\n",
        "                caption = caption + \", \" + caption_suffix.strip()\n",
        "\n",
        "            yield log(f\"   âœï¸  Caption: {caption[:100]}...\"), None, None, gr.update(visible=True)\n",
        "\n",
        "            # Copy video + write caption to local output\n",
        "            dest_video = os.path.join(local_out, f\"{safe_name}.mp4\")\n",
        "            shutil.copy2(video_path, dest_video)\n",
        "\n",
        "            txt_path = os.path.join(local_out, f\"{safe_name}.txt\")\n",
        "            with open(txt_path, 'w', encoding='utf-8') as f:\n",
        "                f.write(caption)\n",
        "\n",
        "            # Copy to Drive if requested\n",
        "            if save_to_drive and os.path.exists('/content/drive'):\n",
        "                shutil.copy2(dest_video, os.path.join(DRIVE_DATASET_DIR, f\"{safe_name}.mp4\"))\n",
        "                shutil.copy2(txt_path,   os.path.join(DRIVE_DATASET_DIR, f\"{safe_name}.txt\"))\n",
        "                yield log(f\"   ğŸ’¾ Saved to Drive!\"), None, None, gr.update(visible=True)\n",
        "\n",
        "            results_data.append({\"filename\": orig_name, \"caption\": caption, \"status\": \"âœ… Done\"})\n",
        "            yield log(f\"   âœ… Done!\\n\"), None, None, gr.update(visible=True)\n",
        "\n",
        "        except Exception as e:\n",
        "            err_msg = str(e)\n",
        "            yield log(f\"   âŒ FAILED: {err_msg}\\n\"), None, None, gr.update(visible=True)\n",
        "            results_data.append({\"filename\": orig_name, \"caption\": f\"ERROR: {err_msg}\", \"status\": \"âŒ Failed\"})\n",
        "            continue\n",
        "\n",
        "    # â”€â”€ Create ZIP â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "    yield log(\"ğŸ“¦ Creating dataset ZIP...\"), None, None, gr.update(visible=True)\n",
        "    zip_path = f\"/content/wan21_dataset_{timestamp}.zip\"\n",
        "    with zipfile.ZipFile(zip_path, 'w', zipfile.ZIP_DEFLATED) as zf:\n",
        "        for root, dirs, files in os.walk(local_out):\n",
        "            for file in files:\n",
        "                fp = os.path.join(root, file)\n",
        "                arcname = os.path.relpath(fp, local_out)\n",
        "                zf.write(fp, arcname)\n",
        "\n",
        "    # Save manifest JSON\n",
        "    manifest_path = os.path.join(local_out, 'dataset_manifest.json')\n",
        "    manifest = {\n",
        "        \"created_at\": timestamp,\n",
        "        \"model_used\": model_id,\n",
        "        \"caption_style\": caption_style,\n",
        "        \"total_videos\": len(video_files),\n",
        "        \"successful\": sum(1 for r in results_data if r['status'] == 'âœ… Done'),\n",
        "        \"entries\": results_data,\n",
        "    }\n",
        "    with open(manifest_path, 'w') as f:\n",
        "        json.dump(manifest, f, indent=2)\n",
        "\n",
        "    success_count = sum(1 for r in results_data if 'âœ…' in r['status'])\n",
        "    yield log(f\"\\nğŸ‰ COMPLETE! {success_count}/{len(video_files)} videos captioned successfully.\"), None, None, gr.update(visible=True)\n",
        "    yield log(f\"ğŸ“¦ ZIP ready for download: {zip_path}\"), None, None, gr.update(visible=True)\n",
        "    if save_to_drive:\n",
        "        yield log(f\"ğŸ’¾ Dataset also saved to: {DRIVE_DATASET_DIR}\"), None, None, gr.update(visible=True)\n",
        "\n",
        "    # Build results table\n",
        "    table_data = [[r['status'], r['filename'], r['caption'][:120] + ('...' if len(r['caption']) > 120 else '')] for r in results_data]\n",
        "\n",
        "    yield \"\\n\".join(logs), zip_path, table_data, gr.update(visible=True)\n",
        "\n",
        "\n",
        "def validate_api_key(api_key):\n",
        "    \"\"\"Quick test call to check if the API key is valid.\"\"\"\n",
        "    if not api_key.strip():\n",
        "        return \"âš ï¸ Please enter an API key.\"\n",
        "    try:\n",
        "        resp = requests.get(\n",
        "            \"https://openrouter.ai/api/v1/models\",\n",
        "            headers={\"Authorization\": f\"Bearer {api_key.strip()}\"},\n",
        "            timeout=10\n",
        "        )\n",
        "        if resp.status_code == 200:\n",
        "            models = resp.json().get('data', [])\n",
        "            return f\"âœ… API key valid! {len(models)} models available.\"\n",
        "        else:\n",
        "            return f\"âŒ Invalid key (HTTP {resp.status_code}). Check your OpenRouter dashboard.\"\n",
        "    except Exception as e:\n",
        "        return f\"âŒ Connection error: {str(e)}\"\n",
        "\n",
        "\n",
        "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
        "# GRADIO UI\n",
        "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
        "\n",
        "CSS = \"\"\"\n",
        "@import url('https://fonts.googleapis.com/css2?family=Space+Mono:wght@400;700&family=DM+Sans:wght@300;400;500;700&display=swap');\n",
        "\n",
        "* { box-sizing: border-box; }\n",
        "\n",
        "body, .gradio-container {\n",
        "    background: #0a0a0f !important;\n",
        "    color: #e8e8f0 !important;\n",
        "    font-family: 'DM Sans', sans-serif !important;\n",
        "}\n",
        "\n",
        ".gradio-container {\n",
        "    max-width: 1100px !important;\n",
        "    margin: 0 auto !important;\n",
        "}\n",
        "\n",
        "#header {\n",
        "    background: linear-gradient(135deg, #0d0d1a 0%, #1a0a2e 50%, #0a1a2e 100%);\n",
        "    border: 1px solid #2a2a4a;\n",
        "    border-radius: 16px;\n",
        "    padding: 32px;\n",
        "    margin-bottom: 24px;\n",
        "    text-align: center;\n",
        "    position: relative;\n",
        "    overflow: hidden;\n",
        "}\n",
        "#header::before {\n",
        "    content: '';\n",
        "    position: absolute; inset: 0;\n",
        "    background: radial-gradient(ellipse at 50% 0%, rgba(120,60,255,0.15) 0%, transparent 60%);\n",
        "    pointer-events: none;\n",
        "}\n",
        "#header h1 {\n",
        "    font-family: 'Space Mono', monospace !important;\n",
        "    font-size: 2rem !important;\n",
        "    font-weight: 700 !important;\n",
        "    background: linear-gradient(90deg, #a78bfa, #60a5fa, #34d399) !important;\n",
        "    -webkit-background-clip: text !important;\n",
        "    -webkit-text-fill-color: transparent !important;\n",
        "    margin: 0 0 8px 0 !important;\n",
        "    letter-spacing: -1px;\n",
        "}\n",
        "#header p {\n",
        "    color: #888 !important;\n",
        "    font-size: 0.95rem !important;\n",
        "    margin: 0 !important;\n",
        "}\n",
        "\n",
        ".panel {\n",
        "    background: #111120 !important;\n",
        "    border: 1px solid #1e1e3a !important;\n",
        "    border-radius: 12px !important;\n",
        "    padding: 20px !important;\n",
        "}\n",
        "\n",
        "label {\n",
        "    color: #a0a0c0 !important;\n",
        "    font-size: 0.85rem !important;\n",
        "    font-weight: 500 !important;\n",
        "    letter-spacing: 0.5px !important;\n",
        "    text-transform: uppercase !important;\n",
        "}\n",
        "\n",
        "input, textarea, select {\n",
        "    background: #0d0d1f !important;\n",
        "    border: 1px solid #2a2a4a !important;\n",
        "    border-radius: 8px !important;\n",
        "    color: #e0e0ff !important;\n",
        "    font-family: 'DM Sans', sans-serif !important;\n",
        "}\n",
        "input:focus, textarea:focus {\n",
        "    border-color: #7c3aed !important;\n",
        "    box-shadow: 0 0 0 2px rgba(124,58,237,0.2) !important;\n",
        "}\n",
        "\n",
        ".gr-button-primary {\n",
        "    background: linear-gradient(135deg, #7c3aed, #2563eb) !important;\n",
        "    border: none !important;\n",
        "    border-radius: 10px !important;\n",
        "    font-family: 'Space Mono', monospace !important;\n",
        "    font-weight: 700 !important;\n",
        "    font-size: 1rem !important;\n",
        "    padding: 14px 28px !important;\n",
        "    letter-spacing: 1px !important;\n",
        "    transition: all 0.2s ease !important;\n",
        "    box-shadow: 0 4px 20px rgba(124,58,237,0.4) !important;\n",
        "}\n",
        ".gr-button-primary:hover {\n",
        "    transform: translateY(-2px) !important;\n",
        "    box-shadow: 0 8px 30px rgba(124,58,237,0.6) !important;\n",
        "}\n",
        "\n",
        ".gr-button-secondary {\n",
        "    background: transparent !important;\n",
        "    border: 1px solid #2a2a4a !important;\n",
        "    border-radius: 8px !important;\n",
        "    color: #888 !important;\n",
        "    font-family: 'DM Sans', sans-serif !important;\n",
        "}\n",
        "\n",
        "#log_box textarea {\n",
        "    font-family: 'Space Mono', monospace !important;\n",
        "    font-size: 0.78rem !important;\n",
        "    background: #05050e !important;\n",
        "    color: #4ade80 !important;\n",
        "    border: 1px solid #0d2010 !important;\n",
        "    border-radius: 8px !important;\n",
        "    line-height: 1.6 !important;\n",
        "}\n",
        "\n",
        ".step-badge {\n",
        "    display: inline-block;\n",
        "    background: rgba(124,58,237,0.2);\n",
        "    border: 1px solid rgba(124,58,237,0.4);\n",
        "    border-radius: 6px;\n",
        "    padding: 2px 10px;\n",
        "    font-family: 'Space Mono', monospace;\n",
        "    font-size: 0.75rem;\n",
        "    color: #a78bfa;\n",
        "    margin-bottom: 12px;\n",
        "}\n",
        "\n",
        ".pill {\n",
        "    display: inline-flex; align-items: center; gap: 6px;\n",
        "    background: rgba(52,211,153,0.1);\n",
        "    border: 1px solid rgba(52,211,153,0.3);\n",
        "    border-radius: 999px;\n",
        "    padding: 4px 14px;\n",
        "    font-size: 0.8rem;\n",
        "    color: #34d399;\n",
        "    margin: 4px;\n",
        "}\n",
        "\"\"\"\n",
        "\n",
        "HEADER_HTML = \"\"\"\n",
        "<div id=\"header\">\n",
        "    <h1>ğŸ¬ Wan 2.1 Dataset Creator</h1>\n",
        "    <p>Upload videos â†’ AI vision model extracts frames â†’ generates training captions â†’ ready dataset</p>\n",
        "    <div style=\"margin-top:16px; display:flex; flex-wrap:wrap; justify-content:center; gap:4px;\">\n",
        "        <span class=\"pill\">âœ… Auto frame extraction</span>\n",
        "        <span class=\"pill\">âœ… OpenRouter vision LLM</span>\n",
        "        <span class=\"pill\">âœ… Google Drive sync</span>\n",
        "        <span class=\"pill\">âœ… ZIP download</span>\n",
        "        <span class=\"pill\">âœ… Caption prefix/suffix</span>\n",
        "    </div>\n",
        "</div>\n",
        "\"\"\"\n",
        "\n",
        "with gr.Blocks(css=CSS, title=\"Wan 2.1 Dataset Creator\") as demo:\n",
        "\n",
        "    gr.HTML(HEADER_HTML)\n",
        "\n",
        "    with gr.Row():\n",
        "        # â”€â”€ LEFT COLUMN: Config â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "        with gr.Column(scale=1, elem_classes=\"panel\"):\n",
        "            gr.HTML('<div class=\"step-badge\">STEP 1 â€” API</div>')\n",
        "\n",
        "            api_key_input = gr.Textbox(\n",
        "                label=\"ğŸ”‘ OpenRouter API Key\",\n",
        "                placeholder=\"sk-or-v1-...\",\n",
        "                type=\"password\",\n",
        "                info=\"Get your free key at openrouter.ai\",\n",
        "            )\n",
        "            validate_btn = gr.Button(\"Test API Key\", size=\"sm\", variant=\"secondary\")\n",
        "            api_status = gr.Markdown(\"\")\n",
        "\n",
        "            gr.HTML('<hr style=\"border-color:#1e1e3a; margin:16px 0\">')\n",
        "            gr.HTML('<div class=\"step-badge\">STEP 2 â€” MODEL</div>')\n",
        "\n",
        "            model_dropdown = gr.Dropdown(\n",
        "                choices=list(OPENROUTER_MODELS.keys()),\n",
        "                value=\"ğŸ”¥ Google Gemini 2.0 Flash (Fast & Cheap)\",\n",
        "                label=\"ğŸ¤– Vision LLM Model\",\n",
        "                info=\"Free models marked with (Free)\",\n",
        "            )\n",
        "\n",
        "            caption_style_dropdown = gr.Dropdown(\n",
        "                choices=list(CAPTION_STYLES.keys()),\n",
        "                value=\"Wan T2V Training (Detailed)\",\n",
        "                label=\"âœï¸ Caption Style\",\n",
        "            )\n",
        "\n",
        "            custom_prefix_box = gr.Textbox(\n",
        "                label=\"Custom Prompt (if Custom style selected)\",\n",
        "                placeholder=\"Describe this video for AI training...\",\n",
        "                lines=2,\n",
        "                visible=False,\n",
        "            )\n",
        "\n",
        "            def toggle_custom(style):\n",
        "                return gr.update(visible=(style == \"Custom (use prefix box below)\"))\n",
        "            caption_style_dropdown.change(toggle_custom, caption_style_dropdown, custom_prefix_box)\n",
        "\n",
        "            gr.HTML('<hr style=\"border-color:#1e1e3a; margin:16px 0\">')\n",
        "            gr.HTML('<div class=\"step-badge\">STEP 3 â€” OPTIONS</div>')\n",
        "\n",
        "            n_frames_slider = gr.Slider(\n",
        "                minimum=1, maximum=8, value=4, step=1,\n",
        "                label=\"ğŸ–¼ï¸ Frames to extract per video\",\n",
        "                info=\"More frames = better captions, higher cost\",\n",
        "            )\n",
        "\n",
        "            caption_prefix_box = gr.Textbox(\n",
        "                label=\"Caption Prefix (prepended to every caption)\",\n",
        "                placeholder=\"e.g. cinematic style,\",\n",
        "                value=\"\",\n",
        "            )\n",
        "            caption_suffix_box = gr.Textbox(\n",
        "                label=\"Caption Suffix (appended to every caption)\",\n",
        "                placeholder=\"e.g. high quality, 4K\",\n",
        "                value=\"\",\n",
        "            )\n",
        "\n",
        "            drive_checkbox = gr.Checkbox(\n",
        "                label=\"ğŸ’¾ Auto-save to Google Drive\",\n",
        "                value=True,\n",
        "                info=\"Saves to MyDrive/Wan21_QLoRA/dataset/\",\n",
        "            )\n",
        "\n",
        "        # â”€â”€ RIGHT COLUMN: Upload + Run â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "        with gr.Column(scale=1, elem_classes=\"panel\"):\n",
        "            gr.HTML('<div class=\"step-badge\">STEP 4 â€” UPLOAD VIDEOS</div>')\n",
        "\n",
        "            video_upload = gr.File(\n",
        "                label=\"ğŸ“¤ Upload Video Files\",\n",
        "                file_count=\"multiple\",\n",
        "                file_types=[\".mp4\", \".mov\", \".webm\", \".avi\", \".mkv\"],\n",
        "                height=160,\n",
        "            )\n",
        "\n",
        "            run_btn = gr.Button(\n",
        "                \"ğŸš€  GENERATE DATASET\",\n",
        "                variant=\"primary\",\n",
        "                size=\"lg\",\n",
        "            )\n",
        "\n",
        "            gr.HTML('<hr style=\"border-color:#1e1e3a; margin:16px 0\">')\n",
        "            gr.HTML('<div class=\"step-badge\">LIVE LOG</div>')\n",
        "\n",
        "            log_output = gr.Textbox(\n",
        "                label=\"\",\n",
        "                lines=14,\n",
        "                max_lines=14,\n",
        "                interactive=False,\n",
        "                elem_id=\"log_box\",\n",
        "                placeholder=\"Waiting for upload and processing...\",\n",
        "            )\n",
        "\n",
        "    # â”€â”€ Results row â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "    with gr.Row(visible=False) as results_row:\n",
        "        with gr.Column(scale=2):\n",
        "            gr.HTML('<div class=\"step-badge\" style=\"margin-top:16px\">RESULTS</div>')\n",
        "            results_table = gr.Dataframe(\n",
        "                headers=[\"Status\", \"Filename\", \"Caption (preview)\"],\n",
        "                datatype=[\"str\", \"str\", \"str\"],\n",
        "                label=\"Generated Captions\",\n",
        "                wrap=True,\n",
        "                row_count=5,\n",
        "            )\n",
        "        with gr.Column(scale=1):\n",
        "            gr.HTML('<div class=\"step-badge\" style=\"margin-top:16px\">DOWNLOAD</div>')\n",
        "            zip_download = gr.File(\n",
        "                label=\"ğŸ“¦ Download Dataset ZIP\",\n",
        "                interactive=False,\n",
        "            )\n",
        "\n",
        "    # â”€â”€ How-to info â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "    with gr.Accordion(\"ğŸ“– How to use & Dataset Format\", open=False):\n",
        "        gr.Markdown(\"\"\"\n",
        "### Dataset Format\n",
        "Each video produces two files with the same base name:\n",
        "```\n",
        "dataset/\n",
        "  my_clip.mp4       â† original video (copied)\n",
        "  my_clip.txt       â† AI-generated caption\n",
        "  another.mp4\n",
        "  another.txt\n",
        "  dataset_manifest.json  â† metadata about the run\n",
        "```\n",
        "This exact format is what the **Wan 2.1 QLoRA Training notebook** expects.\n",
        "\n",
        "### Getting an OpenRouter API Key\n",
        "1. Go to [openrouter.ai](https://openrouter.ai)\n",
        "2. Sign up (free)\n",
        "3. Go to Keys â†’ Create Key\n",
        "4. Several models are completely **free** to use (marked with `:free`)\n",
        "\n",
        "### Tips for Best Captions\n",
        "- Use **4â€“6 frames** for action-heavy videos\n",
        "- Use **Gemini 2.0 Flash** for speed + quality balance\n",
        "- Add a **caption prefix** like `\"cinematic 4K,\"` to style all captions consistently\n",
        "- The **Wan T2V Training** style is tuned for this model specifically\n",
        "        \"\"\")\n",
        "\n",
        "    # â”€â”€ Wire events â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "    validate_btn.click(\n",
        "        validate_api_key,\n",
        "        inputs=[api_key_input],\n",
        "        outputs=[api_status],\n",
        "    )\n",
        "\n",
        "    run_btn.click(\n",
        "        process_videos,\n",
        "        inputs=[\n",
        "            video_upload, api_key_input, model_dropdown,\n",
        "            caption_style_dropdown, custom_prefix_box,\n",
        "            n_frames_slider, drive_checkbox,\n",
        "            caption_prefix_box, caption_suffix_box,\n",
        "        ],\n",
        "        outputs=[log_output, zip_download, results_table, results_row],\n",
        "    )\n",
        "\n",
        "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
        "# LAUNCH\n",
        "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
        "demo.queue(max_size=5)\n",
        "demo.launch(\n",
        "    share=True,          # generates a public gradio.live link\n",
        "    debug=False,\n",
        "    show_error=True,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k9twTnF3uLGQ",
        "outputId": "376b2ab3-66f3-4348-e608-907d6f9eb675"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    }
  ]
}